from fastapi import APIRouter
from schemas.chat_schemas import ChatRequest, ChatResponse

from services.llm_service import get_llm_response, get_llm_response_memory
from services.memory_service import get_memory, save_memory,trim_memory

router = APIRouter()





@router.post("/chat-with-memory", response_model=ChatResponse)
def chat(request: ChatRequest):
    session_id = request.session_id

    # 1Ô∏è‚É£ Get existing memory
    history = get_memory(session_id)

    # 2Ô∏è‚É£ Add user message
    history.append({
        "role": "user",
        "content": request.message
    })

    # 3Ô∏è‚É£ Call LLM with memory
    reply = get_llm_response_memory(history)

    # 4Ô∏è‚É£ Add assistant reply
    history.append({
        "role": "assistant",
        "content": reply
    })

    # 5Ô∏è‚É£ Trim memory (IMPORTANT üî•)
    history = trim_memory(history)

    # 6Ô∏è‚É£ Save back to Redis
    save_memory(session_id, history)

    return ChatResponse(response=reply)
